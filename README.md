# GATK4 Snakemake Pipeline (gatk4-mainline)

A reproducible Snakemake workflow implementing a **GATK4-based pipeline through final SNP annotation + reporting**:

**download â†’ reference prep â†’ FASTQ retrieval â†’ alignment â†’ sort â†’ mark duplicates â†’ BAM index â†’ HaplotypeCaller â†’ hard-filter â†’ PASS-only known-sites â†’ BQSR â†’ ApplyBQSR â†’ (optional BQSR 2nd pass + plots) â†’ HaplotypeCaller (recal) â†’ split SNP/INDEL (recal) â†’ final hard-filter â†’ SnpEff annotation â†’ per-sample + combined CSV report**

Minimal required inputs on a clean clone:

âœ… `config.yaml` + `accessions.txt`

---

## ğŸ“Œ Project Goals

- Minimal inputs: **`config.yaml`** + **`accessions.txt`**
- Reproducible execution via **Snakemake + per-rule conda envs** (`--use-conda`)
- Modular rule organization under `rules/`
- WSL2 + Ubuntu friendly

---

## âœ… Implemented Steps (Current)

For each accession / sample:

1. **Reference prep (chr15)**
   - Download Ensembl chr15 FASTA (`.fa.gz` â†’ `.fa`)
   - Create `.fai` (samtools faidx)
   - Create `.dict` (GATK CreateSequenceDictionary)
   - Build **BWA index** for canonical `reference/chr_15.fa`

2. **FASTQ download**
   - SRA Toolkit download + conversion to gzipped paired FASTQs
   - Auto-generate `samples.tsv` (for inspection; not required as an input)

3. **Alignment + BAM processing**
   - Align with `bwa mem` â†’ SAM
   - Sort â†’ `results/bam/<sample>.sorted.bam`
   - Mark duplicates (Picard) â†’ `results/dedup/<sample>.dedup.bam`
   - Build BAM index (Picard) â†’ `results/dedup/<sample>.dedup.bai`

4. **Step 4 â€” Call Variants**
   - GATK4 `HaplotypeCaller`
   - Output: `results/vcfs/<sample>.raw_variants.vcf` (first-pass call)

5. **Step 5 â€” Split Variants**
   - `SelectVariants` â†’ `raw_snps.vcf` + `raw_indels.vcf`

6. **Step 6 â€” Filter SNPs**
   - `VariantFiltration` â†’ `filtered_snps.vcf` (tags FAIL in FILTER, keeps PASS)

7. **Step 7 â€” Filter INDELs**
   - `VariantFiltration` â†’ `filtered_indels.vcf` (tags FAIL in FILTER, keeps PASS)

8. **Step 8 â€” Exclude Filtered Variants**
   - `SelectVariants --exclude-filtered`
   - Outputs PASS-only known-sites:
     - `bqsr_snps.vcf`
     - `bqsr_indels.vcf`

9. **Step 9 â€” BQSR #1**
   - `BaseRecalibrator`
   - Output: `results/bqsr/<sample>.recal_data.table`

10. **Step 10 â€” Apply BQSR**
   - `ApplyBQSR`
   - Output: `results/bqsr/<sample>.recal_reads.bam` (**analysis-ready BAM**)

11. **Step 11 â€” BQSR #2 (optional)**
   - `BaseRecalibrator` on `recal_reads.bam`
   - Output: `results/bqsr/<sample>.post_recal_data.table`

12. **Step 12 â€” AnalyzeCovariates (optional; requires Step 11)**
   - `AnalyzeCovariates`
   - Outputs:
     - `results/bqsr/<sample>.recalibration_plots.pdf`
     - `results/bqsr/<sample>.recalibration_plots.csv`

13. **Step 13 â€” Call Variants again (post-BQSR)**
   - GATK4 `HaplotypeCaller` on `recal_reads.bam`
   - Output: `results/vcfs/<sample>.raw_variants_recal.vcf`

14. **Step 14 â€” Split Variants again (post-BQSR SNP vs INDEL)**
   - `SelectVariants` on `raw_variants_recal.vcf`
   - Outputs:
     - `results/vcfs/<sample>.raw_snps_recal.vcf`
     - `results/vcfs/<sample>.raw_indels_recal.vcf`

15. **Step 15 â€” Final Filter SNPs (post-BQSR)**
   - `VariantFiltration` on `raw_snps_recal.vcf`
   - Output:
     - `results/vcfs/<sample>.filtered_snps_final.vcf`
     - `results/vcfs/<sample>.filtered_snps_final.vcf.idx`

16. **Step 16 â€” Final Filter INDELs (post-BQSR)**
   - `VariantFiltration` on `raw_indels_recal.vcf`
   - Output:
     - `results/vcfs/<sample>.filtered_indels_final.vcf`
     - `results/vcfs/<sample>.filtered_indels_final.vcf.idx`

17. **Step 17 â€” Annotate Final SNPs (SnpEff)**
   - `snpEff` on `filtered_snps_final.vcf`
   - Outputs:
     - `results/vcfs/<sample>.filtered_snps_final.ann.vcf`
     - `results/vcfs/<sample>.snpeff_summary.html`
     - `results/vcfs/<sample>.snpEff_genes.txt` (gene list extracted from ANN field)

18. **Step 18 â€” Compile Statistics (CSV report)**
   - `bin/parse_metrics.sh` generates a per-sample report:
     - `results/reports/<sample>.report.csv`
   - A combined report is then generated:
     - `results/reports/report.csv`

---

## ğŸ§¾ accessions.txt (Comments Supported)

Lines starting with `#` are ignored, so you can keep optional accessions ready:

```text
SRR2584863
# SRR2584866
# SRR2584868
```
Uncomment later if time/disk allow.

---

## ğŸ“ Folder Structure
gatk4-snakemake/  
â”œâ”€â”€ Snakefile  
â”œâ”€â”€ config.yaml  
â”œâ”€â”€ accessions.txt  
â”œâ”€â”€ scripts/  
â”‚   â””â”€â”€ download_fastq.sh  
â”œâ”€â”€ envs/  
â”‚   â”œâ”€â”€ bwa.yml  
â”‚   â”œâ”€â”€ picard.yml  
â”‚   â”œâ”€â”€ reference.yml  
â”‚   â”œâ”€â”€ sra-tools.yml  
â”‚   â”œâ”€â”€ gatk.yml  
â”‚   â””â”€â”€ snpeff.yml  
â”œâ”€â”€ rules/  
â”‚   â”œâ”€â”€ download_fastq.smk  
â”‚   â”œâ”€â”€ reference.smk  
â”‚   â”œâ”€â”€ align.smk  
â”‚   â”œâ”€â”€ sort_bam.smk  
â”‚   â”œâ”€â”€ metrics.smk  
â”‚   â”œâ”€â”€ mark_duplicates.smk  
â”‚   â”œâ”€â”€ index_bam.smk  
â”‚   â”œâ”€â”€ haplotypecaller.smk  
â”‚   â”œâ”€â”€ select_variants.smk  
â”‚   â”œâ”€â”€ filter_snps.smk  
â”‚   â”œâ”€â”€ filter_indels.smk  
â”‚   â”œâ”€â”€ exclude_filtered_variants.smk  
â”‚   â”œâ”€â”€ bqsr.smk  
â”‚   â”œâ”€â”€ analyze_covariates.smk  
â”‚   â”œâ”€â”€ haplotypecaller_recal.smk  
â”‚   â”œâ”€â”€ select_variants_recal.smk  
â”‚   â”œâ”€â”€ filter_snps_final.smk  
â”‚   â”œâ”€â”€ filter_indels_final.smk  
â”‚   â”œâ”€â”€ snpeff_annotate.smk  
â”‚   â””â”€â”€ compile_report.smk  
â”œâ”€â”€ bin/  
â”‚   â””â”€â”€ parse_metrics.sh  
â”œâ”€â”€ reference/           # generated  
â”œâ”€â”€ fastq/               # generated  
â”œâ”€â”€ results/             # generated  
â”‚   â”œâ”€â”€ bam/  
â”‚   â”œâ”€â”€ metrics/  
â”‚   â”œâ”€â”€ dedup/  
â”‚   â”œâ”€â”€ vcfs/  
â”‚   â”œâ”€â”€ bqsr/  
â”‚   â”œâ”€â”€ reports/  
â”‚   â””â”€â”€ logs/  
â””â”€â”€ .snakemake/          # generated (conda env cache, metadata, logs)  
---

## ğŸš€ Installing on a Clean WSL2 + Ubuntu System

### 1ï¸âƒ£ Install WSL2 + Ubuntu
wsl --install

### 2ï¸âƒ£ Clone the Repository Inside WSL
cd ~
git clone git@github.com:rcrefcoeur/gatk4-snakemake.git
cd gatk4-snakemake
git checkout gatk4-mainline  

### 3ï¸âƒ£ Install Miniconda
cd ~
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh  
bash Miniconda3-latest-Linux-x86_64.sh  
source ~/.bashrc  

### 4ï¸âƒ£ Create a Snakemake â€œdriverâ€ environment

This env is only to run Snakemake. Rule-specific envs come from envs/*.yml via --use-conda.

conda install -n base -c conda-forge mamba -y  
mamba create -n snakemake -c conda-forge -c bioconda -y snakemake  
conda activate snakemake  

---

## ğŸ” GitHub Authentication in WSL

### SSH (Recommended)
ssh-keygen -t ed25519 -C "your_email@example.com"  
eval "$(ssh-agent -s)"  
ssh-add ~/.ssh/id_ed25519  
cat ~/.ssh/id_ed25519.pub  

Add this key at: https://github.com/settings/ssh/new  

Test:  
ssh -T git@github.com  

Clone via SSH:  
git clone git@github.com:rcrefcoeur/gatk4-snakemake.git  

---

## âš™ Configuration
### BQSR second pass toggle
bqsr_second_pass controls whether Steps 11â€“12 run.
- Recommended default: false (faster; still produces analysis-ready BAM at Step 10)
- Set to true if you want the recalibration report (AnalyzeCovariates plots)  
Example:  
bqsr_second_pass: false  

### Directory keys
Common keys in config.yaml:
- accessions_file, fastq_dir, samples.tsv
- reference_base_url, references, reference_canonical, reference_dir
- bam_dir, metrics_dir, dedup_dir, vcf_dir, bqsr_dir

---

## â–¶ï¸ Running the Workflow
### Dry run (validate DAG)  
snakemake -n -p --use-conda --cores 1 results/dedup/SRR2584863.dedup.bai

### Run final outputs directly (useful targets)
# Final annotated SNP VCF
snakemake -p --use-conda --cores 1 results/vcfs/SRR2584863.filtered_snps_final.ann.vcf

# Per-sample report
snakemake -p --use-conda --cores 1 results/reports/SRR2584863.report.csv

# Combined report
snakemake -p --use-conda --cores 1 results/reports/report.csv

### Run everything in rule all
snakemake -p --use-conda --cores 4 --rerun-incomplete --keep-going

---

## ğŸ§  Notes / Troubleshooting

- If Snakemake says Nothing to be done, all outputs requested by your targets (or rule all) already exist and are up to date.
- snpEff downloads large databases on first run. If you hit Java memory errors, increase heap with:
   - java -Xmx4g -jar ... style, or configure your snpEff call to use more memory.
- parse_metrics.sh is called via bash bin/parse_metrics.sh ... so it does not need executable permissions.

---

## ğŸ‘¤ Contact
For issues or contributions, open a GitHub issue or pull request.
remco.crefcoeur@students.fhnw.ch
---